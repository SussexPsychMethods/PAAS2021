<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lecture 2: Philosophy of Science</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr Lincoln Colling" />
    <meta name="date" content="2021-10-07" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <meta name="description" content="We try to answer the question:  &#39;What is this thing called &quot;science&quot;?&#39;"/>
    <meta week="02"/>
    <meta content_type="slides"/>
    <script src="libs/js-cookie-3.0.0/js.cookie.js"></script>
    <script src="libs/peerjs-1.3.1/peerjs.min.js"></script>
    <script src="libs/tiny.toast-1.0.0/toast.min.js"></script>
    <link href="libs/xaringanExtra-broadcast-0.2.6/broadcast.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-broadcast-0.2.6/broadcast.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Lecture 2: Philosophy of Science
## What is this thing called science?
### Dr Lincoln Colling
### 07 October 2021

---








&lt;br /&gt;


&lt;br /&gt;

.big[.center[**It is university policy to recommend mask wearing**]]

&lt;br /&gt;

.big[.center[**Masks are available if you need one**]]

---

## Philosophy of Science 

The title of this course is "Psychology as a Science". 

- But what is this thing called "Science"? 

- Is it a special way of learning about the world?

- And if it is then what makes it special?

---

## The common-sense view of science

The common-sense view might go something like this:

&gt; Science is special because it is knowledge **based on facts**

Science is often contrasted with other forms of knowledge that might be 
  - based on authority (e.g., celebrities, religious and political leaders)
  
  - revelation (e.g., personal religious or spiritual experiences)
  
  - superstition (e.g., "knowledge of the ancients")
  
  
&lt;br&gt;

But this raises two questions:
1. If science is based on facts, then where do "facts" come from?

2. And how is knowledge then derived from these facts

---

## Where do facts come from?

The **common-sense view of science** was formalised by two schools of thought: The _empiricists_ and the _positivists_
&lt;br&gt;

Together they held a view that went something like this:

&gt; _Knowledge should be derived from the facts of experience_
&lt;br&gt;

We can break this idea down:

1. Careful and unbiased observers can directly access facts through the senses/observation. 

2. Facts come before and are independent of, theories.

3. Facts form a firm and reliable base for scientific knowledge. 

&lt;br&gt;
**But is this true?**

---

## Facts through the senses 


A simple story of a how the senses work is that there are some external physical causes (light, sound waves etc.) that produce some physical changes in our sense organs (e.g., our eyes) that are then registered by the brain. 

This account implies direct and unmediated access to the world through our senses. But is this actually the case?

.pull-left[
&lt;img style="display:flex;margin-left:auto;margin-right:auto" width="60%" src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/My_Wife_and_My_Mother-in-Law.jpg/777px-My_Wife_and_My_Mother-in-Law.jpg" /&gt;]
.pull-right[ - This image could be seen as an old woman or a young woman. Some of you might see one and not the other while some might see both and switch between them.

- The physical causes (the light hitting our eyes) is more-or-less the same for everyone, but you might "see" different things]

---

### Observation is not "theory-free"

The previous example is just a toy example, but it reveals a larger point:

Two scientists might "observe" something different even when looking at the same thing.
&lt;br&gt;
In some fields, being able to make "observations" actually requires training.
1. Training in how to observe stuff through a microscope 

2. Training in how to distinguish different kinds of behaviour 

3. Training in how to read an x-ray etc

So a simple claim that observations are "unbiased" or "straightforwardly given by the senses" seems to be false.

---

## But what do we even mean by "facts"?

When we think of a "fact" there are two things we could mean 

1. "Fact" could refer to some external state of the world 

2. Or **statements** about  those external states

_The fact that **this university is in East Sussex**_ could refer to this actual university and its actual being in East Sussex 

or it could refer to the statement: "This university is in East Sussex."

When we talk about "facts" as the basis for science, we're talking about these statements.

We'll call this type of fact an "observation statement."

---

## Do facts come **before** theories?

Think of a child learning the word apple:

&gt; They might initially imitate the word "apple" when shown an apple by their parent. 

&gt; Next, they might use the word "apple" when pointing to apples

&gt; But then one day they might see a tennis ball and say "apple". The parent would then correct them, and show them that a tennis ball isn't an apple because you can't, for example, bite into it like an apple

&gt; By the time the child can make accurate "observation statements" about the presence of apples they might already know a lot about the properties of apples (have an extensive "theory of apples")

The same goes for scientists; formulating observation statements might require substantial background knowledge or a conceptual framework to place them in.

So **observation statements** aren't completely **independent of theory**

---

## Not just facts, but relevant facts

Let's say that we've been able to acquire some facts. Will any old facts do?

Let's take a simple example: 

&gt; You observe that grass grows longer among the cowpats in a field. 

&gt; - You think this is because the dung traps moisture that helps the grass grow. 

&gt; - Your friend thinks this is because the dung acts as a fertiliser

Observations alone can't distinguish these. To tell which is correct you need to **intervene** on the situation. 

For example, grind up the dung so that it still fertilises the ground or use something else to trap the moisture. 

**Intervening**, for example, through experiment allows you to tell what the _relevant facts_ of your observation are 

---

## Active observation and intervention

By intervening on the system, we can tell which facts are **relevant**

**But** _scientific theories_ may play a part in helping to determine what is and isn't relevant

&gt; Example from the history of *cognitive psychology* 
&gt;
&gt; In certain kinds of reading tasks psychologists thought it was relevant **that** people made errors, but they didn't think the **exact nature of the errors** was relevant.

&gt; But after certain kinds of theories were developed (ones based on neural network models) they came to realise that the particular **kinds of errors** (e.g., if people swapped letters between words) was relevant.

In short, observations can't be completely divorced from theories.

And experiments will presume the truth of certain theories (e.g., brain imaging experiments assume the validity of certain theories about brain function).


---

## "Objectivity"

&lt;blockquote&gt;
Fact's don't care about your feelings
.right[— &lt;cite&gt;Guy on the internet&lt;/cite&gt;]
&lt;/blockquote&gt;


The idea that science is **objective** in a _simple sense_ of "objectivity" is misleading. 

Your **conceptual framework**, and **theoretical assumptions**, and even your **knowledge and training** can play **a part** in *what kinds of observations* you can make or *what types of observation statements you can formulate*

"Objectivity" **.red[doesn't mean]** observations free from theoretical assumptions ("the view from nowhere")

---

### "Objectivity" is more complex

"Objectivity" **.green[does mean]**
  - **Publicly** and independently verifiable methods
  - **Recognising** theoretical assumptions
  - **Theory/data that are open to revision** and improvement
  - Free from **avoidable** forms of bias (confounds, cherry picking data, experimenter bias)
  
It is also **objective** in the sense that despite all this, when you make the observations either the behaviour will happen or it won't, the detector will flash or it won't etc. _Your theory can't make things happen_.
  

---

## Deriving theories from facts

The second part of the **common-sense** view of science is that scientific knowledge is **derived** from facts. 

Usually this idea of **derived** means something like **logically derived**. We might sum up the view like this:

&lt;blockquote&gt;
Science = Facts + Logic  
.right[— &lt;cite&gt;Guy on the internet&lt;/cite&gt;]
&lt;/blockquote&gt;


&lt;br&gt;
To understand what it might mean to **logically** derive scientific knowledge we need to know a bit about **logic**

---

### Deductive logic

A deductive argument is called **valid** if the conclusions follow from the premises. 

&lt;div style="font-size:smaller"&gt;
.pull-left[
**Example 1**   
1. All research methods lectures are boring    
2. This is a research methods lecture    
3. (Therefore) this lecture is boring    

In this example, if we accept that (1) and (2) are true, then we have to accept (3) as true. We cannot accept (1) and (2) as true and then deny that (3) is true because we would be contradicting ourselves.
]

.pull-right[**Example 2**
1. Most research methods lectures are boring   
2. This is a research methods lecture     
3. (Therefore) this lecture is boring      

In our new example, we can accept (1) and (2) as true without accepting (3) as true. That is, (3) does not **necessarily follow** from (1) and (2). It might just be a case of a research methods lecture that isn't boring.]
&lt;br&gt;
&lt;/div&gt;


Deduction was only concerned with whether (3) follows from  (1) and (2). Not concerned with determining whether (1) and (2) are true or false. The argument assumes that (1) and (2) _are_ true, but it doesn't establish **truth** 

---

### False but valid

.pull-left[**Example 3**   
1. All pigs can fly   
2. Percy is a pig   
3. (Therefore) Percy can fly.    ]

.pull-right[The conclusion is **valid**. However, it is also **false** because (1) is false.

It is **valid** because if we accept (1) and (2) we can have to accept (3)
]

**logic** only tells us what follows from what. If there is truth in our premises, then there is truth in our conclusions. 
&lt;br&gt;

If our premises are false, then our conclusions will also be false.
&lt;br&gt;

Deductive logic is **truth-preserving**, but it can't tell us what is true and what is false. And the conclusion is just a *re-statement of the information contained in the premises*

So **deductive logic** can't create new knowledge. What can you do instead?

We need a way to go from **particular observations** to **generalizations** (this process is called **induction**)

---

## Induction

We need a way to construct arguments of the following form:

**Premises**    
1. Emily the swan is white   
2. Kevin the swan is white   
3. ... the swan is white   
 
**Conclusion**    
All swans are white   

But the problem with arguments like this is that _all the premises may be true and yet the conclusion can be false_

**Maybe** we just haven't observed the one swan that ** isn't white**?

---

## Collecting observations

But surely there are .green[good] and .red[bad] **inductive** arguments?

- **More** observations better than **fewer** observations—_but how many is enough?_

- Observations in many **different contexts**—_but what makes a context different and what makes differences **relevant**?_    
	- Different contexts should be **novel** in some sense     
	- That is, it should **not** just be **trivial** changes   

- No **contradicting observations**—_but what about **probabilistic** phenomena_?

**Clear** and **simple** rules aren't easy to come by.

But the bigger problem is **induction can never establish truth**.

So how do we ever **prove anything for certain in science**. The short answer is, **we don't**.

We can **never be certain** of **truth**.   

---

## Using induction and deduction

 Instead of just **collecting** _confirmations_ we can employ **induction** and **deduction**

.pull-left[
&lt;img style="display:flex;margin-left:auto;margin-right:auto" src="inductive-deductive.png"&gt;&lt;/img&gt;
]

.pull-right[
- Collect observations and use **induction** to come up with **general laws** and theories from **particular observations**

- Use deduction to figure out what **logically follows** from these general laws and theories]

This approach nicely captures the idea of **testability**

Our **theories** should make **predictions** about what we **expect to find** and we can **test** these predictions with more observations

---

## Deduction and knowing what is **false**

The philosopher _Karl Popper_ also saw trouble with relying on **induction**. He wanted to put science on a firmer logical footing.

To do this, he proposed that while scientists can't use **deduction** to figure out what is **true**, they can use **deduction** to figure out what is **false**


He suggested that a key quality of **scientific theories** is that they should be **falsifiable**.

Theories can come into existence through any means (wild speculation, guesses, dreams, or whatever), but once a theory has been proposed it has to be **rigorously and ruthlessly tested**

---

### Falsification of theories

.pull-left[
**Confirmation**     
**Premise:** A swan that was white was spotted in London at time *t*   

**Conclusion:** All swans are white.   

Conclusion might be **true** or **false**, but it doesn't **logically** follow from the premise 
]

.pull-right[
**Falsification**     
**Premise:** A swan, which was not white, was spotted in Australia at time *t*.    

**Conclusion:** Not all swans are white.   

Conclusion **logically** follows from the premise, so if the premise is **true** the conclusion is **true**. 
]

We can't **prove** the claim "_all swans are white_", but we can **reject it.**

---

## Degrees of **falsifiability**

**Good** theories are *falsifiable*, **better** theories are **_more falsifiable_**

**Three theories:**   

1. Mars moves in an elliptical orbit    
2. Mars and Venus move in elliptical orbits   
3. Planets move in elliptical orbits   

Of these three theories, (1) is the least falsifiable and (3) is the most falsifiable. Why? For theory (1) only an observation of Mars could falsify it. But for theory (3), an observation Mars, Venus, Saturn, Neptune, or any other yet undiscovered planet would falsify it.

Bad theories are ones that can seemingly accommodate **any observation**

If **two outcomes** are possible and the theory can explain **outcome one** and **outcome two** then this is **bad**. What would be **evidence against the theory**?

**.green[Good]** theories are **broad** in their **_applicability_** but **precise** in their **_predictions_**  

---

## Encountering a falsifier

What happens when you make an observation that falsifies a theory?

That is, you observe something that **contradicts** the theory you're testing. What do you do?

**Your options:**

- You could _abandon the theory_    
	- But what about _probabilistic theories_?   
	- And what about _auxiliary assumptions_?    
	 
- You could _modify or amend the theory_   
	- But are their _better_ ways and _worse_ ways to do this?   

---

## Probabilistic theories 

Theories in **psychology** tend to be **probabilistic**. They make claims about how things are **on average**, not claims about how things are **in every case**.&lt;sup&gt;1&lt;/sup&gt;

Much of what we do with **statistics** is figuring out how to **test** and **specify** **probabilistic claims**. For example:    
- What does it mean for things to be different **on average**    
- How many cases do you have to observe before you have **evidence for** a probabilistic claim   
- How many cases do you have to observe before you have **evidence against** a probabilistic claim (that you might previously have believed)    

But putting that aside, a **single** contradictory observation can't falsify a probabilistic claim because we will **sometimes expect** contradictions with probabilistic claims.

.footnote[&lt;sup&gt;1&lt;/sup&gt;A probabilistic claim might say something like _on average_ "men are taller than women", but of course there are shorter men and taller women.]

---

## Abandoning the theory

Putting aside the probabilistic nature of claims (or assuming you've seen enough contradictory examples), should these contradictory observations lead you to abandon the theory?

Any experiment is not testing **one theory in isolation** but also relies on a range of auxiliary assumptions and other support theories.

For example, an experiment on memory using brain imaging is also making assumptions about the truth of theories related to physics and brain functioning, **besides** testing the theory about memory).

---

### The Duhem-Quine problem

It **may be the case** that what is actually at fault is one of these auxiliary assumptions and not **your theory**.  Telling which part of the **interconnected web** of theories is at fault can be tricky. Philosophers call this the _Duhem-Quine problem_.

_Popper_ didn't have a good answer on how to figure out where to lay the blame for an _apparent_ falsification.

_Popper_ also didn't think that theories should be abandoned _too quickly_.

He suggested some _dogmatism_, because at the start scientists might still be figuring out the details, and therefore they might just need to make some _tweaks_ and modify their theories.


---


## Revising and amending theories

But if we decide to amend a theory, then how do we do this?

**Theory**: All bread is nourishing     
**Observation:** Bread eaten in a French village in 1951 was not nourishing&lt;sup&gt;1&lt;/sup&gt;   


**.red[Ad-hoc modification]**     
_All bread expect bread eaten in a French village in 1951 is nourishing_     

Modification has fewer tests: Original theory can be tested by eating any bread. Modified theory can be tested by eating any bread **except** that particular bread.


**.green[Acceptable modification]**   
_All bread except bread made with flour containing ergot fungus is nourishing_

Modification leads to new tests: 1) Test the bread for the presence of fungus; 2) Cultivate fungus and make bread with it and test whether it nourishes; 3) Analyse fungus for poisons.   

.footnote[&lt;sup&gt;1&lt;/sup&gt;https://en.wikipedia.org/wiki/1951_Pont-Saint-Esprit_mass_poisoning]


---

## Problems with Popper's falsificationism  

_Popper's_ focus on **falsifying** theories leads to a couple of problems:

1. It can be difficult to figure out when to **abandon** theories and when to **amend** theories. 

  - Are all parts of the **theoretical web** of the same status?

2. It can difficult to compare two theories to see which is "better"
  - For example, if you have **Theory  A** and **Theory B** and neither has been falsified, which is the better theory? The one with _more **confirming** observations_? But then won't **trivial theories** will always win?


The philosopher _Imre Lakatos_ developed his idea of **research programmes**&lt;sup&gt;1&lt;/sup&gt; as a reaction to these two problems.
 
.footnote[&lt;sup&gt;1&lt;/sup&gt;A _similar_ idea was developed by the philosopher _Thomas Kuhn_, but _Kuhn_ used the term **paradigms** for his idea.]

---

## Research programmes

One key aspect of _Lakatos's_ idea of **research programmes** is that not all **parts of a science are on par**

- Some laws or principles are so fundamental they might be considered a **defining part of the science**.

- Other parts might be more peripheral

_Lakatos_ called these fundamental parts the **hard core** and the more peripheral parts the **protective belt**

He suggested that the **hard core** is resistant to _falsification_, so when an apparent falsifier is observed the blame is placed on theories in the **protective belt** 

**Research programmes** are defined by what is in their **hard core**

---

### Hard cores and protective belts

What is in the **hard core** and what is in the **protective belt** might not always be explicit, but these might be some examples:

- In Cognitive Science the **hard core** might include the theory that mind/brain is a _particular kind of computational system_ and the **protective belt** might include specific theories about how memory works

- In the biomedical view of mental illness the **hard core** might include the theory that mental illness can be explained biochemically and the **protective belt** might include the dopamine theory of schizophrenia

When apparent falsifications occur the **protective belt** is up for revision but the **hard core** stays intact. Falsifying the **hard core** amounts to abandoning the _research programme_ (more on this later)

---

## Working within a research programme

On _Latakos's_ view, scientists work **within a research programme**. 

He split guidelines for working within a research programme into a **negative** and **positive** heuristic, specifying what scientists **shouldn't** do but also what they **should** do

- The _negative heuristic_ includes things like not abandoning the **hard core**

- The _positive heuristic_ is harder to specify exactly, but it includes suggestions on how to supplement the protective belt to develop the research programme further

	- That is, it should specify a **programme of research** 

	- The **research programme** should identify problems to solve

---

### Example of a research programme

&lt;img style="display:flex;margin-left:auto;margin-right:auto;width:65%"  src="hardcore.png" /&gt;

&lt;caption&gt;Example of a research programme from Dienes (2008)&lt;/caption&gt;

---

## Progressive / degenerating programmes

_Lakatos_ was also interested in comparing **research programmes**, something that is difficult to do on a _strictly_ falsificationist account.

He divided research programmes into those that are **progressive** and those that are **degenerating**

- Progressive research programmes are coherent (i.e., have minimal contradictions)

	- And progressive research programmes make **novel** predictions that **follow naturally** from theories that are part of the programmes

	- These predictions are then confirmed by experiments

- Degenerating research programmes are those that have faced so many falsifications that they have been modified to the point of being incoherent. 

	- At this point, it's no longer sustainable to carry on modifying the protective belt, and instead, the hard core must be abandoned 

---

### Moving from one programme to another

When the hard core is abandoned then scientists move from one research programme into a new one. 

Some examples of this in psychology might include:
1. The move from psychological behaviourism to cognitive science 
2. From classical cognitive science to embodied cognitive science
3. From connectionism to deep neural networks 
4. From sociobiology to evolutionary psychology

But again, what is and isn't a **research programme** isn't always clear, because often the **hard core** and the **protective belt** are left _implicit_ and not made _explicit_

However, I think it's valuable to keep these distinctions in mind as you move through your university career.

---


.center[**Any Questions?**]

.center[&lt;img src="qrcode.svg" width="65%"&gt;]

.center[https://pollev.com/drcolling]



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
